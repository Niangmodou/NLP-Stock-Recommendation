{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYLwhmM7UKVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q yahoo_fin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gpq3LPIT30_j",
        "colab_type": "text"
      },
      "source": [
        "### Importing Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TI5UgDX30_m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "f61ff616-2e20-48ee-86c4-190698dd7468"
      },
      "source": [
        "import requests\n",
        "import http\n",
        "from requests.adapters import HTTPAdapter\n",
        "from requests.packages.urllib3.util.retry import Retry\n",
        "\n",
        "import pandas as pd\n",
        "from yahoo_fin import stock_info\n",
        "from pandas_datareader import DataReader\n",
        "import numpy as np\n",
        "import urllib3\n",
        "from urllib.request import urlopen, Request\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning - Certain functionality \n",
            "             requires requests_html, which is not installed.\n",
            "             \n",
            "             Install using: \n",
            "             pip install requests_html\n",
            "             \n",
            "             After installation, you may have to restart your Python session.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas_datareader/compat/__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  from pandas.util.testing import assert_frame_equal\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWJm9H6a30_w",
        "colab_type": "text"
      },
      "source": [
        "### Retrieving S&P 500 stock information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dUR0PSa30_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to retrieve S&P 500 recommendations from Yahoo Finance\n",
        "def get_recommendations(tickers):\n",
        "    recommendations = []\n",
        "    \n",
        "    for ticker in tickers:\n",
        "  \n",
        "        #Yahoo Finance URL for current stock ticker\n",
        "        url = 'https://query2.finance.yahoo.com/v10/finance/quoteSummary/'\n",
        "        url+= ticker\n",
        "        url += '?formatted=true&crumb=swg7qs5y9UP&lang=en-US&region=US&' \\\n",
        "                'modules=upgradeDowngradeHistory,recommendationTrend,' \\\n",
        "                'financialData,earningsHistory,earningsTrend,industryTrend&' \\\n",
        "                'corsDomain=finance.yahoo.com'\n",
        "                  \n",
        "        data = requests.get(url)\n",
        "        if(not data.ok):\n",
        "            recommendataion = -1\n",
        "        \n",
        "        #Parsing JSON response to retrieve recommendation rating\n",
        "        try:\n",
        "          result = data.json()['quoteSummary']['result'][0]\n",
        "          recommendation = result['financialData']['recommendationMean']['fmt']\n",
        "        except:\n",
        "          recommendation = -1\n",
        "\n",
        "        recommendations.append(recommendation)\n",
        "    \n",
        "    return recommendations\n",
        "\n",
        "\n",
        "#S&P 500 Tickers\n",
        "tickers = stock_info.tickers_sp500()\n",
        "recommendations = get_recommendations(tickers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJQzvyRh30_4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "9c6a5bf1-6ab7-4aed-c6a2-197ea8b8a7fd"
      },
      "source": [
        "#Creating a dataframe with stocks and their respective recommendations\n",
        "columns = ['Company','Recommendations']\n",
        "data = pd.DataFrame(list(zip(tickers,recommendations)), columns = columns)\n",
        "\n",
        "#Converting Recommendations column to float\n",
        "data['Recommendations'] = pd.to_numeric(data['Recommendations'])\n",
        "\n",
        "data = data[data.Recommendations != -1]\n",
        "\n",
        "data.sort_values(by=['Recommendations'],)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Recommendations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>PWR</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>LKQ</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>BSX</td>\n",
              "      <td>1.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>DXCM</td>\n",
              "      <td>1.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>J</td>\n",
              "      <td>1.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAL</td>\n",
              "      <td>3.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>ED</td>\n",
              "      <td>3.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>BEN</td>\n",
              "      <td>3.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309</th>\n",
              "      <td>MKC</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>477</th>\n",
              "      <td>WAT</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>501 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Company  Recommendations\n",
              "387     PWR              1.5\n",
              "284     LKQ              1.5\n",
              "72      BSX              1.6\n",
              "150    DXCM              1.6\n",
              "255       J              1.6\n",
              "..      ...              ...\n",
              "1       AAL              3.3\n",
              "154      ED              3.4\n",
              "61      BEN              3.4\n",
              "309     MKC              3.5\n",
              "477     WAT              3.6\n",
              "\n",
              "[501 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3s5BskAAkyP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "b6960f63-60a7-43e6-83ba-c876e190f03e"
      },
      "source": [
        "#Creating Seperate DataFrames to house hold, sell and buy stocka\n",
        "hold = data[data.Recommendations == 3]\n",
        "buy = data[data.Recommendations <= 1.5]\n",
        "sell = data[data.Recommendations >= 4.5]\n",
        "\n",
        "#Combining theses data frames into one big DF\n",
        "data_lst = [buy,hold,sell]\n",
        "new_data = pd.concat(data_lst)\n",
        "new_data.reset_index(level = 0, inplace = True)\n",
        "\n",
        "new_data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Company</th>\n",
              "      <th>Recommendations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>284</td>\n",
              "      <td>LKQ</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>387</td>\n",
              "      <td>PWR</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>ALLE</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>97</td>\n",
              "      <td>CLX</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>119</td>\n",
              "      <td>CTSH</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>136</td>\n",
              "      <td>DISCK</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>258</td>\n",
              "      <td>JKHY</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>267</td>\n",
              "      <td>KIM</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>274</td>\n",
              "      <td>KSS</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>276</td>\n",
              "      <td>L</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>279</td>\n",
              "      <td>LEG</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>401</td>\n",
              "      <td>ROK</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>418</td>\n",
              "      <td>SO</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>452</td>\n",
              "      <td>UA</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>474</td>\n",
              "      <td>VTR</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index Company  Recommendations\n",
              "0     284     LKQ              1.5\n",
              "1     387     PWR              1.5\n",
              "2      28    ALLE              3.0\n",
              "3      97     CLX              3.0\n",
              "4     119    CTSH              3.0\n",
              "5     136   DISCK              3.0\n",
              "6     258    JKHY              3.0\n",
              "7     267     KIM              3.0\n",
              "8     274     KSS              3.0\n",
              "9     276       L              3.0\n",
              "10    279     LEG              3.0\n",
              "11    401     ROK              3.0\n",
              "12    418      SO              3.0\n",
              "13    452      UA              3.0\n",
              "14    474     VTR              3.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8teIvHTO-Qv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function is used to populate a List with Recommended Stocks from Yahoo Finance\n",
        "def get_tickers(data):\n",
        "  tickers = []\n",
        "\n",
        "  for index, row in data.iterrows():\n",
        "    tickers.append(row.Company)\n",
        "\n",
        "  return tickers\n",
        "\n",
        "#Function is used to fetch news information of stocks recomended by Yahoo Finance\n",
        "def fetch_news(tickers):\n",
        "  news = {}\n",
        "\n",
        "  for ticker in tickers:\n",
        "    url = 'https://finviz.com/quote.ashx?t=' + ticker\n",
        "\n",
        "    #Scraping FinWiz webpage to get news involving current stock\n",
        "    req = requests.get(url=url, headers={'User-Agent':'my-app/0.0.1'}) \n",
        "    response = req.content\n",
        "  \n",
        "\n",
        "    html_page = BeautifulSoup(response)\n",
        "    news_table = html_page.find(id='news-table')\n",
        "    \n",
        "    news[ticker] = news_table\n",
        "\n",
        "  return news\n",
        "\n",
        "tickers = get_tickers(new_data)\n",
        "\n",
        "news = fetch_news(tickers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65og1xWTQo5z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "a9e8120d-ecce-42d3-84f5-3ca894658085"
      },
      "source": [
        "#Function is used to parse news info and create a dataframe involving each company and relevant news\n",
        "def news_data(news):\n",
        "  news_table = []\n",
        "\n",
        "  for file_name, curr_news in news.items():\n",
        "    for each in curr_news.findAll('tr'):\n",
        "      \n",
        "      #Scraping News Table to retrieve relevant news and timestamp\n",
        "      text = each.a.get_text()\n",
        "      data = each.td.text.split()\n",
        "\n",
        "      if(len(data) == 1):\n",
        "        time = data[0]\n",
        "      else:\n",
        "        date = data[0]\n",
        "        time = data[1]\n",
        "      \n",
        "      ticker = file_name.split('_')[0]\n",
        "\n",
        "      ticker_info = [ticker,date,time,text]\n",
        "      news_table.append(ticker_info)\n",
        "\n",
        "  #Creating of a DataFrame with ticker and news information\n",
        "  columns = ['Ticker','Date','Time','Headline']\n",
        "  parsed_news = pd.DataFrame(news_table,columns=columns)\n",
        "\n",
        "  parsed_news['Date'] = pd.to_datetime(parsed_news.Date).dt.date\n",
        "\n",
        "  return parsed_news\n",
        "\n",
        "parsed_news = news_data(news)\n",
        "\n",
        "#Grouping the headlines for each comapny into one string\n",
        "parsed_news = parsed_news.groupby(['Ticker'], as_index = False).agg({'Headline':''.join}, Inplace = True)\n",
        "parsed_news"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ticker</th>\n",
              "      <th>Headline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ALLE</td>\n",
              "      <td>Why Is Allegion (ALLE) Down 0.9% Since Last Ea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CLX</td>\n",
              "      <td>Should We Waste This Crisis?Here's what boomin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CTSH</td>\n",
              "      <td>8 Stocks Diamond Hill Capital Continues to Buy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DISCK</td>\n",
              "      <td>John Paulson Adds 2 Stocks to Portfolio, Boost...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>JKHY</td>\n",
              "      <td>UNIFY Financial Credit Union Moving its Symita...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KIM</td>\n",
              "      <td>Here's Why You Should Hold On to Kimco Realty ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>KSS</td>\n",
              "      <td>A Bad Earnings Report for Nordstrom Is Good En...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>L</td>\n",
              "      <td>Dow futures gain as investors watch for earnin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LEG</td>\n",
              "      <td>Edited Transcript of LEG earnings conference c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>LKQ</td>\n",
              "      <td>Jeff Ubben's ValueAct Sells FedEx, Buys 2 New ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>PWR</td>\n",
              "      <td>Quanta Services to Participate in Several Inst...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ROK</td>\n",
              "      <td>Top Industrial Stocks for June 2020Rockwell Au...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>SO</td>\n",
              "      <td>Edited Transcript of SO earnings conference ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>UA</td>\n",
              "      <td>Dow books a 150-point loss after President Tru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>VTR</td>\n",
              "      <td>Top Real Estate Stocks for June 2020Is Healthp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Ticker                                           Headline\n",
              "0    ALLE  Why Is Allegion (ALLE) Down 0.9% Since Last Ea...\n",
              "1     CLX  Should We Waste This Crisis?Here's what boomin...\n",
              "2    CTSH  8 Stocks Diamond Hill Capital Continues to Buy...\n",
              "3   DISCK  John Paulson Adds 2 Stocks to Portfolio, Boost...\n",
              "4    JKHY  UNIFY Financial Credit Union Moving its Symita...\n",
              "5     KIM  Here's Why You Should Hold On to Kimco Realty ...\n",
              "6     KSS  A Bad Earnings Report for Nordstrom Is Good En...\n",
              "7       L  Dow futures gain as investors watch for earnin...\n",
              "8     LEG  Edited Transcript of LEG earnings conference c...\n",
              "9     LKQ  Jeff Ubben's ValueAct Sells FedEx, Buys 2 New ...\n",
              "10    PWR  Quanta Services to Participate in Several Inst...\n",
              "11    ROK  Top Industrial Stocks for June 2020Rockwell Au...\n",
              "12     SO  Edited Transcript of SO earnings conference ca...\n",
              "13     UA  Dow books a 150-point loss after President Tru...\n",
              "14    VTR  Top Real Estate Stocks for June 2020Is Healthp..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzahMcupRnim",
        "colab_type": "text"
      },
      "source": [
        "### Sentiment Analysis"
      ]
    }
  ]
}